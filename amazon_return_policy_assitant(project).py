# -*- coding: utf-8 -*-
"""Amazon Return Policy Assitant(Project).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ptnHtZ__k4m8VV59WgLMtw_dS5bPXQdf
"""

pip install gradio openai faiss-cpu tiktoken sentence-transformers

from google.colab import files
uploaded = files.upload()

import requests
from bs4 import BeautifulSoup

url = "https://www.amazon.in/gp/help/customer/display.html?nodeId=202111910"
html = requests.get(url).text
soup = BeautifulSoup(html, "html.parser")

# Extract only visible text
policy_text = "\n".join([p.get_text(strip=True) for p in soup.find_all("p")])
with open("amazon_return_policy.txt", "w", encoding="utf-8") as f:
    f.write(policy_text)

sample_text = """
Amazon allows returns within 30 days of receipt of shipment.
Items must be in new and unused condition.
Some products (like software, groceries, etc.) may not be eligible.
Refunds are processed within 3‚Äì5 business days after the returned item is received.
Shipping costs may be deducted unless the return is Amazon‚Äôs fault.
"""

with open("amazon_return_policy.txt", "w", encoding="utf-8") as f:
    f.write(sample_text)
print("‚úÖ Sample amazon_return_policy.txt created.")

import os

# Check if file exists and has content
if not os.path.exists("amazon_return_policy.txt") or os.path.getsize("amazon_return_policy.txt") == 0:
    print("‚ö†Ô∏è File is missing or empty. Creating sample policy file...")
    sample_text = """
    Amazon allows returns within 30 days of receipt.
    Some categories like groceries and software may not be eligible.
    Refunds take 3‚Äì5 business days after the item is received.
    Return shipping costs may apply unless the error was Amazon's.
    """
    with open("amazon_return_policy.txt", "w", encoding="utf-8") as f:
        f.write(sample_text)
else:
    print("‚úÖ File found and not empty.")

with open("amazon_return_policy.txt", "r", encoding="utf-8") as f:
    text_chunks = [line.strip() for line in f if line.strip()]

print("üìù Loaded", len(text_chunks), "chunks")

if not text_chunks:
    raise ValueError("‚ùå Text file is still empty after reading. Please check content.")

from sentence_transformers import SentenceTransformer
import faiss

model = SentenceTransformer('all-MiniLM-L6-v2')

# Encode the text
embeddings = model.encode(text_chunks, convert_to_tensor=False)

if len(embeddings) == 0 or len(embeddings[0]) == 0:
    raise ValueError("‚ùå Embedding failed. Check input text.")

dimension = len(embeddings[0])
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

faiss.write_index(index, "policy.index")
print("‚úÖ FAISS index created and saved as 'policy.index'")

# Import libraries
from sentence_transformers import SentenceTransformer
import faiss

# Load sentence transformer model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Example text chunks
text_chunks = [
    "Amazon offers a 30-day return policy on most items.",
    "Electronics must be returned within 15 days.",
    "Items should be in original packaging to be eligible for return."
]

# Generate embeddings
embeddings = model.encode(text_chunks, convert_to_tensor=False)

# Create FAISS index
dimension = len(embeddings[0])  # Get the embedding size
index = faiss.IndexFlatL2(dimension)  # Create index for L2 distance

# Add embeddings to index
index.add(embeddings)

# Perform a search
query = model.encode(["How long do I have to return electronics?"], convert_to_tensor=False)
D, I = index.search(query, k=1)

# Print most similar chunk
print("Most relevant chunk:", text_chunks[I[0][0]])

import gradio as gr
import faiss
from sentence_transformers import SentenceTransformer
import os

# Load files
text_file = "amazon_return_policy.txt"
index_file = "policy.index"

# Read text chunks
with open(text_file, "r", encoding="utf-8") as f:
    text_chunks = [line.strip() for line in f if line.strip()]

# Load model and index
embed_model = SentenceTransformer('all-MiniLM-L6-v2')
index = faiss.read_index(index_file)

# Retrieval function
def retrieve_context(query, k=3):
    q_emb = embed_model.encode([query])
    distances, indices = index.search(q_emb, k)
    return "\n".join([text_chunks[i] for i in indices[0]])

# Chatbot logic
def respond(message, history):
    context = retrieve_context(message)
    response = f"üìÑ Based on Amazon's policy:\n{context}"
    return response

# Gradio Interface
chat_interface = gr.ChatInterface(
    fn=respond,
    chatbot=gr.Chatbot(type="messages", label="Amazon Return Policy Assistant"),
    title="üì¶ Amazon Return Policy Assistant",
    description="Ask any question about Amazon's return policy."
)

chat_interface.launch(share=True, debug=True)